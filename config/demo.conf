// Demo config, replacing old demo.sh with same params.
// Run with:
//   python src/main.py --config_file config/demo.conf
//
// Use this as a template to make your own configs, and see defaults.conf for a 
// comprehensive list of supported parameters.

// This file uses HOCON, which is a JSON/YAML-like format that supports 
// includes, references, and object merging semantics; see 
// https://github.com/lightbend/config/blob/master/HOCON.md for reference. 

// This imports the defaults, which can be overridden below.
include "defaults.conf"  // relative path to this file

exp_name = "jiant-demo"
run_name = "sst"

cuda = 0
random_seed = 42

no_tqdm = 1  // if true, disable tqdm progress bar

load_model = 0
reload_tasks = 0
reload_indexing = 0
reload_vocab = 0
force_load_epoch = -1

train_tasks = "sst"
eval_tasks = "mrpc"
classifier = "mlp"
classifier_hid_dim = 32
max_seq_len = 10
max_word_v_size = 5000

word_embs = "none"
fastText = 0
char_embs = 0
d_word = 300
elmo = 1
elmo_chars_only = 1
cove = 0

sent_enc = "transformer"
bidirectional = 1
skip_embs = 0
d_hid = 32
d_proj = 32
d_hid_attn = 32
pair_enc = "simple"
n_layers_enc = 1
n_layers_highway = 0

batch_size = 16

bpp_base = 1
val_interval = 50
max_vals = 10
eval_val_interval = 10 
eval_max_vals = 10
weighting_method = "uniform"
scaling_method = "none"
warmup=4000

// Tasks specific stuff: either task-specific model parameters or eval-time trainer params
sst_classifier_hid_dim = 32
sst_d_proj = 32
mrpc_classifier_hid_dim = 32
mrpc_d_proj = 32
